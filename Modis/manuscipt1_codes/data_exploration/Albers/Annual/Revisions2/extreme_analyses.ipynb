{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from xarray.core.duck_array_ops import notnull\n",
    "import rasterio\n",
    "import fiona\n",
    "import numpy as np \n",
    "def outliers_index(data, m=3.5):\n",
    "    \"\"\"\n",
    "    Returns true if a value is outlier\n",
    "    https://www.itl.nist.gov/div898/handbook/eda/section3/eda356.htm#MAD\n",
    "    :param int data: numpy array\n",
    "    :param int m: # of std to include data \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    d = np.abs(data - np.nanmedian(data))\n",
    "    mdev = np.nanmedian(d)\n",
    "    s = d / mdev if mdev else 0.\n",
    "    return ~(s < m)\n",
    "\n",
    "\n",
    "def mymask(tif, shp):\n",
    "    # To mask landsat LUC pixels included in each MODIS pixel\n",
    "    out_image, out_transform = rasterio.mask.mask(tif,\n",
    "                                                  shp,\n",
    "                                                  all_touched=False,\n",
    "                                                  crop=True)\n",
    "    # out_meta = tif.meta\n",
    "    # return out_image,out_meta,out_transform\n",
    "    return out_image, out_transform\n",
    "\n",
    "\n",
    "def confusionmatrix(actual, predicted, unique, imap):\n",
    "    \"\"\"\n",
    "    Generate a confusion matrix for multiple classification\n",
    "    @params:\n",
    "        actual      - a list of integers or strings for known classes\n",
    "        predicted   - a list of integers or strings for predicted classes\n",
    "        # normalize   - optional boolean for matrix normalization\n",
    "        unique\t\t- is the unique numbers assigned to each class\n",
    "        imap\t\t- mapping of classes \n",
    "\n",
    "    @return:\n",
    "        matrix      - a 2-dimensional list of pairwise counts\n",
    "    \"\"\"\n",
    "\n",
    "    matrix = [[0 for _ in unique] for _ in unique]\n",
    "    # Generate Confusion Matrix\n",
    "    for p, a in list(zip(actual, predicted)):\n",
    "        if ((p > len(unique)) or (a > len(unique))):\n",
    "            continue\n",
    "        matrix[imap[p]][imap[a]] += 1\n",
    "    # Matrix Normalization\n",
    "    # if normalize:\n",
    "    sigma = sum([sum(matrix[imap[i]]) for i in unique])\n",
    "    matrix_normalized = [\n",
    "        row for row in map(lambda i: list(map(lambda j: j / sigma, i)), matrix)\n",
    "    ]\n",
    "    return matrix, matrix_normalized\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "in_dir = (\"/data/home/hamiddashti/nasa_above/outputs/Natural_Variability/\"\n",
    "          \"Natural_Variability_Annual_outputs/Albers/\")\n",
    "out_dir = (\"/data/home/hamiddashti/mnt/nasa_above/working/modis_analyses/test/\")\n",
    "\n",
    "# out_dir = \"/data/home/hamiddashti/mnt/nasa_above/working/modis_analyses/test/\"\n",
    "\n",
    "dlcc = xr.open_dataarray(in_dir+\"dlcc.nc\")\n",
    "\n",
    "dlst_mean_total = xr.open_dataarray(in_dir + \"dlst_total.nc\", decode_cf=\"all\")\n",
    "dalbedo_total = xr.open_dataarray(in_dir + \"dalbedo_total.nc\")\n",
    "det_total = xr.open_dataarray(in_dir + \"det_total.nc\")\n",
    "det_total = det_total.assign_coords({\n",
    "    \"lat\": dlst_mean_total.lat,\n",
    "    \"lon\": dlst_mean_total.lon\n",
    "})\n",
    "dalbedo_total = dalbedo_total.assign_coords({\n",
    "    \"lat\": dlst_mean_total.lat,\n",
    "    \"lon\": dlst_mean_total.lon\n",
    "})\n",
    "\n",
    "dlst_mean_lcc = xr.open_dataarray(in_dir + \"dlst_lcc.nc\")\n",
    "dalbedo_lcc = xr.open_dataarray(in_dir + \"dalbedo_lcc.nc\")\n",
    "det_lcc = xr.open_dataarray(in_dir + \"det_lcc.nc\")\n",
    "\n",
    "dlst_mean_nv = xr.open_dataarray(in_dir + \"dlst_nv.nc\")\n",
    "dalbedo_nv = xr.open_dataarray(in_dir + \"dalbedo_nv.nc\")\n",
    "det_nv = xr.open_dataarray(in_dir + \"det_nv.nc\")\n",
    "\n",
    "# I_dlst_total = outliers_index(dlst_mean_total)\n",
    "# I_dalbedo_total = outliers_index(dalbedo_total)\n",
    "# I_det_total = outliers_index(det_total)\n",
    "\n",
    "I_dlst_lcc = outliers_index(dlst_mean_lcc)\n",
    "I_dalbedo_lcc = outliers_index(dalbedo_lcc)\n",
    "I_det_lcc = outliers_index(det_lcc)\n",
    "\n",
    "I_dlst_nv = outliers_index(dlst_mean_nv)\n",
    "I_dalbedo_nv = outliers_index(dalbedo_nv)\n",
    "I_det_nv = outliers_index(det_nv)\n",
    "\n",
    "# dlst_total_clean = dlst_mean_total.where((I_dlst_total == False)\n",
    "#                                          & (I_dalbedo_total == False)\n",
    "#                                          & (I_det_total == False))\n",
    "# dalbedo_total_clean = dalbedo_total.where((I_dlst_total == False)\n",
    "#                                           & (I_dalbedo_total == False)\n",
    "#                                           & (I_det_total == False))\n",
    "# det_total_clean = det_total.where((I_dlst_total == False)\n",
    "#                                   & (I_dalbedo_total == False)\n",
    "#                                   & (I_det_total == False))\n",
    "dlst_lcc_clean = dlst_mean_lcc.where((I_dlst_lcc == False)\n",
    "                                     & (I_dalbedo_lcc == False)\n",
    "                                     & (I_det_lcc == False))\n",
    "dalbedo_lcc_clean = dalbedo_lcc.where((I_dlst_lcc == False)\n",
    "                                      & (I_dalbedo_lcc == False)\n",
    "                                      & (I_det_lcc == False))\n",
    "det_lcc_clean = det_lcc.where((I_dlst_lcc == False) & (I_dalbedo_lcc == False)\n",
    "                              & (I_det_lcc == False))\n",
    "\n",
    "dlst_nv_clean = dlst_mean_nv.where((I_dlst_nv == False)\n",
    "                                   & (I_dalbedo_nv == False)\n",
    "                                   & (I_det_nv == False))\n",
    "\n",
    "dalbedo_nv_clean = dalbedo_nv.where((I_dlst_nv == False)\n",
    "                                    & (I_dalbedo_nv == False)\n",
    "                                    & (I_det_nv == False))\n",
    "\n",
    "det_nv_clean = det_nv.where((I_dlst_nv == False) & (I_dalbedo_nv == False)\n",
    "                            & (I_det_nv == False))\n",
    "\n",
    "dlst_lcc_clean = dlst_lcc_clean.where((dlst_nv_clean.notnull())\n",
    "                                      & (dlst_lcc_clean.notnull()))\n",
    "dlst_nv_clean = dlst_nv_clean.where((dlst_nv_clean.notnull())\n",
    "                                    & (dlst_lcc_clean.notnull()))\n",
    "\n",
    "dalbedo_lcc_clean = dalbedo_lcc_clean.where((dalbedo_nv_clean.notnull())\n",
    "                                            & (dalbedo_lcc_clean.notnull()))\n",
    "dalbedo_nv_clean = dalbedo_nv_clean.where((dalbedo_nv_clean.notnull())\n",
    "                                          & (dalbedo_lcc_clean.notnull()))\n",
    "det_lcc_clean = det_lcc_clean.where((det_nv_clean.notnull())\n",
    "                                    & (det_lcc_clean.notnull()))\n",
    "det_nv_clean = det_nv_clean.where((det_nv_clean.notnull())\n",
    "                                  & (det_lcc_clean.notnull()))\n",
    "\n",
    "dlst_total_clean = dlst_nv_clean + dlst_lcc_clean\n",
    "dalbedo_total_clean = dalbedo_nv_clean + dalbedo_lcc_clean\n",
    "det_total_clean = det_nv_clean + det_lcc_clean\n",
    "\n",
    "dlcc_clean = dlcc.where(dlst_lcc_clean.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlst_hot = dlst_lcc_clean.where(dlst_lcc_clean>=1.5)\n",
    "dlst_cold = dlst_lcc_clean.where(dlst_lcc_clean<=-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlcc_hot = xr.where(dlst_hot.notnull(),dlcc,-9999)\n",
    "dlcc_hot_max = dlcc_hot.argmax(\"band\")\n",
    "dlcc_hot_max = dlcc_hot_max.where(dlst_hot.notnull())\n",
    "dlcc_hot_max.to_netcdf(out_dir+\"dlcc_hot_max.nc\")\n",
    "dlst_hot.to_netcdf(out_dir+\"dlst_hot.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlcc_cold = xr.where(dlst_cold.notnull(),dlcc,-9999)\n",
    "dlcc_cold_max = dlcc_cold.argmax(\"band\")\n",
    "dlcc_cold_max = dlcc_cold_max.where(dlst_cold.notnull())\n",
    "dlcc_cold_max.to_netcdf(out_dir+\"dlcc_cold_max.nc\")\n",
    "\n",
    "dlst_cold = dlst_cold.where(dlst_cold.notnull())\n",
    "dlst_cold.to_netcdf(out_dir+\"dlst_cold.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray ()>\n",
      "array(7.92371618)\n",
      "Coordinates:\n",
      "    spatial_ref  int64 0\n",
      "<xarray.DataArray ()>\n",
      "array(11.77873258)\n",
      "Coordinates:\n",
      "    spatial_ref  int64 0\n"
     ]
    }
   ],
   "source": [
    "total_changed = (dlst_lcc_clean.notnull()).sum()\n",
    "extreme_hot = (dlst_hot.notnull()).sum()\n",
    "extreme_cold = (dlst_cold.notnull()).sum()\n",
    "precent_extreme_hot = extreme_hot*100/total_changed\n",
    "precent_extreme_cold = extreme_cold*100/total_changed\n",
    "print(precent_extreme_hot)\n",
    "print(precent_extreme_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be1200267def26a5c2ca7e56eae4458b75b9485fc42d22e84319b00455e444c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
